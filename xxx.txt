1.针对每种类别的衣服分别训练网络？5个不同类别。(测试时显式告知所属类别)测试时根据所属类别载入不同的模型。
2.存在但被遮挡的关键点预测出的结果该如何？设置一个阈值用以截断预测出的heatmap的最大值，若小于阈值，则判定被遮挡，否则则未被遮挡。
3.crop后测试时的坐标转换？
4.mse的计算，先把gt_heatmap resize到指定大小再算？
5.同一类别下也可能存在不同数量的关节点。。。。为了取batch来进行训练(要求维度一致)，只能按照同一类别关键点相同来进行训练了。
6.图像的大小也不一定都是512*512.。。。我敲立马,同上，需要先resize
7.双线性插值后的坐标转换？
    依据biliear插值的实现是中心对齐的：
    先将坐标变为相对于原图中心点的相对坐标，并计算放缩的scale，resize到新的坐标下后将相对坐标乘以scale再加上新的中心点坐标即可。
8.直接根据关节点crop好像边缘不太好。
9.对于被遮挡的点，heatmap置为全零，那么如何预测对应的关节点坐标？或者说被遮挡的点heatmap照常生成，那么预测出关节点后如何判断是否被遮挡？
10.crop时根据边界再往外增加几个像素点。(TO HAVE A TRY)
11.最前面的detecor是否需要。self_tracker,先根据第一次输入的测试图得到一个坐标值，然后根据坐标值确定一个粗略的框，再根据这个框crop测试图再输入一次得到新的坐标值。
12.数据增强，坐标如何计算？
13.不分类别，直接全类别进行训练，不存在或被遮挡的点全标0。(TODO)
14.对于不存在的点容易预测为存在的点。。
15.训练时不该crop？否则测试时偏离太大。。。？
16.使用stn来保证人物在中心位置以减小偏差。loss使用mse